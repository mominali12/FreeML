{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "000a33da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data22/mal/.pyenv/versions/env_flex_vit/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "import torch\n",
    "import torchvision\n",
    "from torchsummary import summary\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# import wandb\n",
    "# os.environ[\"WANDB_API_KEY\"] = \"a5512fb941c1661aa83748cacb0811fdccefd461\"\n",
    "# run = wandb.init(project=\"DScale\", name=\"slimmable-S_test\")\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "width_mult_list = [0.25, 0.5, 0.75, 1.0]\n",
    "\n",
    "def make_divisible(v, divisor=8, min_value=1):\n",
    "    \"\"\"\n",
    "    forked from slim:\n",
    "    https://github.com/tensorflow/models/blob/\\\n",
    "    0344c5503ee55e24f0de7f37336a6e08f10976fd/\\\n",
    "    research/slim/nets/mobilenet/mobilenet.py#L62-L69\n",
    "    \"\"\"\n",
    "    if min_value is None:\n",
    "        min_value = divisor\n",
    "    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n",
    "    # Make sure that round down does not go down by more than 10%.\n",
    "    if new_v < 0.9 * v:\n",
    "        new_v += divisor\n",
    "    return new_v\n",
    "\n",
    "\n",
    "class SlimmableConv2d(nn.Conv2d):\n",
    "    def __init__(self, in_channels_list, out_channels_list,\n",
    "                 kernel_size, stride=1, padding=0, dilation=1,\n",
    "                 groups_list=[1], bias=True):\n",
    "        super(SlimmableConv2d, self).__init__(\n",
    "            max(in_channels_list), max(out_channels_list),\n",
    "            kernel_size, stride=stride, padding=padding, dilation=dilation,\n",
    "            groups=max(groups_list), bias=bias)\n",
    "        self.in_channels_list = in_channels_list\n",
    "        self.out_channels_list = out_channels_list\n",
    "        self.groups_list = groups_list\n",
    "        if self.groups_list == [1]:\n",
    "            self.groups_list = [1 for _ in range(len(in_channels_list))]\n",
    "        self.width_mult = max(width_mult_list)\n",
    "\n",
    "    def forward(self, input):\n",
    "        idx = width_mult_list.index(self.width_mult)\n",
    "        self.in_channels = self.in_channels_list[idx]\n",
    "        self.out_channels = self.out_channels_list[idx]\n",
    "        self.groups = self.groups_list[idx]\n",
    "        weight = self.weight[:self.out_channels, :self.in_channels, :, :]\n",
    "        if self.bias is not None:\n",
    "            bias = self.bias[:self.out_channels]\n",
    "        else:\n",
    "            bias = self.bias\n",
    "        y = nn.functional.conv2d(\n",
    "            input, weight, bias, self.stride, self.padding,\n",
    "            self.dilation, self.groups)\n",
    "        return y\n",
    "\n",
    "\n",
    "class SlimmableLinear(nn.Linear):\n",
    "    def __init__(self, in_features_list, out_features_list, bias=True):\n",
    "        super(SlimmableLinear, self).__init__(\n",
    "            max(in_features_list), max(out_features_list), bias=bias)\n",
    "        self.in_features_list = in_features_list\n",
    "        self.out_features_list = out_features_list\n",
    "        self.width_mult = max(width_mult_list)\n",
    "\n",
    "    def forward(self, input):\n",
    "        idx = width_mult_list.index(self.width_mult)\n",
    "        self.in_features = self.in_features_list[idx]\n",
    "        self.out_features = self.out_features_list[idx]\n",
    "        weight = self.weight[:self.out_features, :self.in_features]\n",
    "        if self.bias is not None:\n",
    "            bias = self.bias[:self.out_features]\n",
    "        else:\n",
    "            bias = self.bias\n",
    "        return nn.functional.linear(input, weight, bias)\n",
    "\n",
    "\n",
    "class Baseline(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Baseline, self).__init__()\n",
    "        out_channels_1 = [int(64 * width_mult) for width_mult in width_mult_list]\n",
    "        #3 input channels for conv1 because input is rgb image\n",
    "        self.conv1 = SlimmableConv2d([3 for _ in range(len(width_mult_list))], out_channels_1, kernel_size=3, padding=\"valid\",bias= False)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "\n",
    "        out_channels_2 = [ int(128 * width_mult) for width_mult in width_mult_list]\n",
    "        self.conv2 = SlimmableConv2d(out_channels_1, out_channels_2, kernel_size=3, padding=\"valid\",bias= False)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "\n",
    "        out_channels_3 = [ int(64 * width_mult) for width_mult in width_mult_list]\n",
    "        self.conv3 = SlimmableConv2d(out_channels_2, out_channels_3, kernel_size=3, padding=\"valid\",bias= False)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "\n",
    "        #b,64,2,2\n",
    "        self.flatten = nn.Flatten()\n",
    "        #b,64x4\n",
    "        out_channels_fc1 = [ int(256 * width_mult) for width_mult in width_mult_list]\n",
    "        self.fc1 = SlimmableLinear([i*4 for i in out_channels_3], out_channels_fc1)\n",
    "\n",
    "        out_channels_fc2 = [ int(64 * width_mult) for width_mult in width_mult_list]\n",
    "        self.fc2 = SlimmableLinear(out_channels_fc1, out_channels_fc2)\n",
    "\n",
    "        out_channels_fc3 = [10 for _ in range(len(width_mult_list))]\n",
    "        self.fc3 = SlimmableLinear(out_channels_fc2, out_channels_fc3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        exit_outputs = []\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool1(x)\n",
    "        exit_outputs.append(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool2(x)\n",
    "        exit_outputs.append(x)\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool3(x)\n",
    "        exit_outputs.append(x)\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x, exit_outputs\n",
    "\n",
    "dataset = CIFAR10(root='/home/mal/DScale/freeml/FreeML/EarlyExit/CIFAR-10/data', download=True, transform=ToTensor())\n",
    "test_dataset = CIFAR10(root='/home/mal/DScale/freeml/FreeML/EarlyExit/CIFAR-10/data', train=False, transform=ToTensor())\n",
    "\n",
    "epochs = 1\n",
    "batch_size=128\n",
    "val_size = 5000\n",
    "train_size = len(dataset) - val_size\n",
    "# wandb.config.update({\"epochs\": epochs, \"batch_size\": batch_size, \"val_size\": val_size, \"train_size\": train_size}, allow_val_change=True)\n",
    "train_ds, val_ds = random_split(dataset, [train_size, val_size])\n",
    "train_loader = DataLoader(train_ds, batch_size, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_ds, batch_size*2, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size*2, num_workers=4)\n",
    "\n",
    "model = Baseline().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=3e-3, momentum=0.9)\n",
    "\n",
    "best_val_epoch, best_val_loss = 0, 1e6\n",
    "break_flag = 0\n",
    "for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "    model.train()\n",
    "    t_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for width_mult in sorted(width_mult_list, reverse=True):\n",
    "        model.apply(\n",
    "        lambda m: setattr(m, 'width_mult', width_mult))\n",
    "\n",
    "        for i, data in enumerate(train_loader):\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs, _ = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            t_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        t_loss = t_loss / (i+1)\n",
    "        t_loss = round(t_loss, 5)\n",
    "        t_acc = round(100*(correct / total), 5)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e03c01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11ed8675",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ca17492",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "330939de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Baseline(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Baseline, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=1, padding=0)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=\"valid\")\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "        self.conv3 = nn.Conv2d(in_channels=128, out_channels=64, kernel_size=3, stride=1, padding=\"valid\")\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=256, out_features=256)\n",
    "        self.fc2 = nn.Linear(in_features=256, out_features=64)\n",
    "        self.fc3 = nn.Linear(in_features=64, out_features=10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        exit_outputs = []\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool1(x)\n",
    "        exit_outputs.append(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool2(x)\n",
    "        exit_outputs.append(x)\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool3(x)\n",
    "        exit_outputs.append(x)\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x, exit_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "95b57c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline(\n",
      "  232.33 k, 100.000% Params, 15.44 MMac, 98.971% MACs, \n",
      "  (conv1): Conv2d(1.79 k, 0.771% Params, 1.61 MMac, 10.339% MACs, 3, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (pool1): MaxPool2d(0, 0.000% Params, 57.6 KMac, 0.369% MACs, kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(73.86 k, 31.789% Params, 12.48 MMac, 80.017% MACs, 64, 128, kernel_size=(3, 3), stride=(1, 1), padding=valid)\n",
      "  (pool2): MaxPool2d(0, 0.000% Params, 21.63 KMac, 0.139% MACs, kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv3): Conv2d(73.79 k, 31.762% Params, 1.18 MMac, 7.569% MACs, 128, 64, kernel_size=(3, 3), stride=(1, 1), padding=valid)\n",
      "  (pool3): MaxPool2d(0, 0.000% Params, 1.02 KMac, 0.007% MACs, kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  (flatten): Flatten(0, 0.000% Params, 0.0 Mac, 0.000% MACs, start_dim=1, end_dim=-1)\n",
      "  (fc1): Linear(65.79 k, 28.318% Params, 65.79 KMac, 0.422% MACs, in_features=256, out_features=256, bias=True)\n",
      "  (fc2): Linear(16.45 k, 7.080% Params, 16.45 KMac, 0.105% MACs, in_features=256, out_features=64, bias=True)\n",
      "  (fc3): Linear(650, 0.280% Params, 650.0 Mac, 0.004% MACs, in_features=64, out_features=10, bias=True)\n",
      ")\n",
      "FLOPs: 15.6 MMac\n",
      "Parameters: 232.33 k\n"
     ]
    }
   ],
   "source": [
    "from ptflops import get_model_complexity_info\n",
    "\n",
    "input_size = (3, 32, 32) \n",
    "model = Baseline()\n",
    "model = model.to(device)\n",
    "\n",
    "# Calculate FLOPs and parameters\n",
    "flops, params = get_model_complexity_info(model, input_size, as_strings=True, print_per_layer_stat=True)\n",
    "\n",
    "# Print the results\n",
    "print(f\"FLOPs: {flops}\")\n",
    "print(f\"Parameters: {params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42fdf788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class IndividualEEModel(nn.Module):\n",
    "#     def __init__(self, in_features):\n",
    "#         super(IndividualEEModel, self).__init__()\n",
    "#         self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "#         self.flatten = nn.Flatten()\n",
    "#         self.fc1 = nn.Linear(in_features=in_features, out_features=10)\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         x = self.pool(x)\n",
    "#         x = self.flatten(x)\n",
    "#         x = self.fc1(x)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7d31ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IndividualEEModel(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super(IndividualEEModel, self).__init__()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(in_features=in_features, out_features=10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fc9e50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class GeneralEEModel(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(GeneralEEModel, self).__init__()\n",
    "#         self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "#         self.pool1 = nn.MaxPool1d(kernel_size=3, stride=3)\n",
    "#         self.fc1 = nn.Linear(in_features=14400, out_features=32)\n",
    "#         self.fc2 = nn.Linear(in_features=25088, out_features=32)\n",
    "#         self.fc3 = nn.Linear(in_features=10816, out_features=32)\n",
    "#         self.fcs = [self.fc1, self.fc2, self.fc3]\n",
    "#         self.flatten = nn.Flatten()\n",
    "#         self.fc4 = nn.Linear(in_features=32, out_features=10)\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         fc_outs = []\n",
    "#         batch_size = x[0].shape[0]\n",
    "#         for i, x_ in enumerate(x):\n",
    "#             x_ = self.pool(x_)\n",
    "#             x_ = self.flatten(x_)\n",
    "#             x_ = self.fcs[i](x_)\n",
    "#             x_ = F.relu(x_)\n",
    "#             fc_outs.append(x_)\n",
    "#         xx = []\n",
    "#         for i in range(32):\n",
    "#             for j in range(len(fc_outs)):\n",
    "#                 xx.append(torch.reshape(fc_outs[j][:, i], (batch_size, 1)))\n",
    "#         x = torch.cat(xx, dim=1)\n",
    "#         x = torch.unsqueeze(x, 1)\n",
    "#         x = self.pool1(x)\n",
    "#         x = self.flatten(x)\n",
    "#         x = self.fc4(x)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "db51af43",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneralEEModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GeneralEEModel, self).__init__()\n",
    "        self.pool_kernels = [\n",
    "            (1, 6, 6), (1, 3, 3), (1, 1, 1)\n",
    "        ]\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.dropout = nn.Dropout(p=0.4)\n",
    "        self.fc = nn.Linear(in_features=1024, out_features=10)\n",
    "    \n",
    "    def forward(self, x, inference=False):\n",
    "        pooled_outs = []\n",
    "        for layer, out in enumerate(x):\n",
    "            pool_3d = nn.MaxPool3d(kernel_size=self.pool_kernels[layer])\n",
    "            pooled_outs.append(pool_3d(out))\n",
    "        x = torch.cat(pooled_outs, dim=1)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout(x)\n",
    "        scores = self.fc(x)\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "95bbbd70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CombinedModel(\n",
      "  242.58 k, 100.000% Params, 15.45 MMac, 98.850% MACs, \n",
      "  (baseline_model): Baseline(\n",
      "    232.33 k, 95.775% Params, 15.44 MMac, 98.784% MACs, \n",
      "    (conv1): Conv2d(1.79 k, 0.739% Params, 1.61 MMac, 10.320% MACs, 3, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (pool1): MaxPool2d(0, 0.000% Params, 57.6 KMac, 0.369% MACs, kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (conv2): Conv2d(73.86 k, 30.446% Params, 12.48 MMac, 79.866% MACs, 64, 128, kernel_size=(3, 3), stride=(1, 1), padding=valid)\n",
      "    (pool2): MaxPool2d(0, 0.000% Params, 21.63 KMac, 0.138% MACs, kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (conv3): Conv2d(73.79 k, 30.420% Params, 1.18 MMac, 7.555% MACs, 128, 64, kernel_size=(3, 3), stride=(1, 1), padding=valid)\n",
      "    (pool3): MaxPool2d(0, 0.000% Params, 1.02 KMac, 0.007% MACs, kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (flatten): Flatten(0, 0.000% Params, 0.0 Mac, 0.000% MACs, start_dim=1, end_dim=-1)\n",
      "    (fc1): Linear(65.79 k, 27.122% Params, 65.79 KMac, 0.421% MACs, in_features=256, out_features=256, bias=True)\n",
      "    (fc2): Linear(16.45 k, 6.780% Params, 16.45 KMac, 0.105% MACs, in_features=256, out_features=64, bias=True)\n",
      "    (fc3): Linear(650, 0.268% Params, 650.0 Mac, 0.004% MACs, in_features=64, out_features=10, bias=True)\n",
      "  )\n",
      "  (general_ee_model): GeneralEEModel(\n",
      "    10.25 k, 4.225% Params, 10.25 KMac, 0.066% MACs, \n",
      "    (flatten): Flatten(0, 0.000% Params, 0.0 Mac, 0.000% MACs, start_dim=1, end_dim=-1)\n",
      "    (dropout): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.4, inplace=False)\n",
      "    (fc): Linear(10.25 k, 4.225% Params, 10.25 KMac, 0.066% MACs, in_features=1024, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "FLOPs: 15.63 MMac\n",
      "Parameters: 242.58 k\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the models\n",
    "baseline_model = Baseline()\n",
    "general_ee_model = GeneralEEModel()\n",
    "\n",
    "# Define the input tensor for the Baseline model\n",
    "input_tensor = torch.randn(1, 3, 32, 32)  # Batch size 1, 3 channels, 32x32 image\n",
    "\n",
    "# Get the exit outputs from the Baseline model\n",
    "_, exit_outputs = baseline_model(input_tensor)\n",
    "\n",
    "# Define a wrapper model to combine the Baseline and GeneralEEModel\n",
    "class CombinedModel(nn.Module):\n",
    "    def __init__(self, baseline_model, general_ee_model):\n",
    "        super(CombinedModel, self).__init__()\n",
    "        self.baseline_model = baseline_model\n",
    "        self.general_ee_model = general_ee_model\n",
    "\n",
    "    def forward(self, x):\n",
    "        _, exit_outputs = self.baseline_model(x)\n",
    "        scores = self.general_ee_model(exit_outputs)\n",
    "        return scores\n",
    "\n",
    "# Instantiate the combined model\n",
    "combined_model = CombinedModel(baseline_model, general_ee_model)\n",
    "\n",
    "# Calculate FLOPs and parameters using ptflops\n",
    "def calculate_flops(model, input_tensor):\n",
    "    flops, params = get_model_complexity_info(model, (3, 32, 32), as_strings=True, print_per_layer_stat=True)\n",
    "    print(f\"FLOPs: {flops}\")\n",
    "    print(f\"Parameters: {params}\")\n",
    "\n",
    "# Run the FLOPs calculation\n",
    "calculate_flops(combined_model, input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19bff418",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_exit(x, choice=None):\n",
    "    if choice is not None:\n",
    "        choice = choice\n",
    "    else:\n",
    "        choice = np.random.choice(np.arange(0, 3), p=[0.34, 0.33, 0.33])\n",
    "    batch_size = x[0].shape[0]\n",
    "    reshaped_output = []\n",
    "    for i in range(3):\n",
    "        if i <= choice :\n",
    "            reshaped_output.append(x[i])\n",
    "        else:\n",
    "            reshaped_output.append(torch.zeros_like(x[i]))\n",
    "    return reshaped_output, choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "691d54eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(baseline, exit_model, layer, epochs, criterion, \n",
    "          optimizer, train_loader, val_loader, model_name, gen_ee=False):\n",
    "    best_val_epoch, best_val_loss = 0, 1e6\n",
    "    break_flag = 0\n",
    "    for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "        exit_model.train()\n",
    "        t_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for i, data in enumerate(train_loader):\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            _, outs = baseline(images)\n",
    "            if gen_ee:\n",
    "                outs, choice = simulate_exit(outs)\n",
    "                out = outs\n",
    "            else:\n",
    "                out = outs[layer]\n",
    "            outputs = exit_model(out)\n",
    "            loss = criterion(outputs, labels)\n",
    "            t_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        t_loss = t_loss / (i+1)\n",
    "        t_loss = round(t_loss, 5)\n",
    "        t_acc = round(100*(correct / total), 5)\n",
    "        exit_model.eval()\n",
    "        v_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for i, data in enumerate(val_loader):\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            _, outs = baseline(images)\n",
    "            if gen_ee:\n",
    "                outs, choice = simulate_exit(outs)\n",
    "                out = outs\n",
    "            else:\n",
    "                out = outs[layer]\n",
    "            outputs = exit_model(out)\n",
    "            loss = criterion(outputs, labels)\n",
    "            v_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        v_loss = v_loss/(i+1)\n",
    "        v_loss = round(v_loss, 5)\n",
    "        v_acc = round(100*(correct / total), 5)\n",
    "        if v_loss <= best_val_loss:\n",
    "            torch.save(exit_model.state_dict(), model_name)\n",
    "            best_val_epoch = epoch + 1\n",
    "            best_val_loss = v_loss\n",
    "            break_flag = 0\n",
    "        else:\n",
    "            break_flag += 1\n",
    "        print(f'Epoch[{epoch+1}]: t_loss: {t_loss} t_acc: {t_acc} v_loss: {v_loss} v_acc: {v_acc}')\n",
    "        if break_flag >19 :\n",
    "            break\n",
    "    print('Finished Training')\n",
    "    print('Best model saved at epoch: ', best_val_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7ff56fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "dataset = CIFAR10(root='./data', download=True, transform=ToTensor())\n",
    "test_dataset = CIFAR10(root='./data', train=False, transform=ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4020b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=128\n",
    "val_size = 5000\n",
    "pct = .01\n",
    "train_size = int(pct*len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "# train_size = len(dataset) - val_size\n",
    "train_ds, val_ds = random_split(dataset, [train_size, val_size])\n",
    "_, val_ds = random_split(val_ds, [int(0.7*len(val_ds)), len(val_ds) - int(0.7*len(val_ds))])\n",
    "train_loader = DataLoader(train_ds, batch_size, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_ds, batch_size*2, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size*2, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee2397d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Baseline(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=valid)\n",
       "  (pool1): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=valid)\n",
       "  (pool2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv3): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=valid)\n",
       "  (pool3): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=256, out_features=64, bias=True)\n",
       "  (fc3): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline = Baseline().to(device)\n",
    "baseline.load_state_dict(torch.load(\"cifar10_baseline_s_new.h5\", map_location='cpu'))\n",
    "ee_model_name = \"TEST_cifar10_ee_s.h5\"\n",
    "baseline.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4a176d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in_features = []\n",
    "# m = nn.MaxPool2d(kernel_size=2)\n",
    "# f = nn.Flatten()\n",
    "# _, outs = baseline(torch.randn(2, 3, 32, 32).to(device))\n",
    "# for out in outs:\n",
    "#     print(out.shape)\n",
    "#     xx = f(m(out))\n",
    "#     in_features.append(xx.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c27437b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# intermediate_outputs = []\n",
    "# pool_kernels = [(1, 6, 6), (1, 3, 3), (1, 1, 1)]\n",
    "# f = nn.Flatten()\n",
    "# _, outs = baseline(torch.randn(2, 3, 32, 32).to(device))\n",
    "# for i, out in enumerate(outs):\n",
    "#     m = nn.MaxPool3d(kernel_size=pool_kernels[i])\n",
    "#     xx = m(out)\n",
    "#     intermediate_outputs.append(xx)\n",
    "#     print(out.shape, xx.shape)\n",
    "# xx = torch.cat(intermediate_outputs, dim=1)\n",
    "# print(xx.shape)\n",
    "# xx = f(xx)\n",
    "# print(xx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ada52c4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# result_dict = {}\n",
    "# result_dict[\"accuracy\"] = []\n",
    "# for ii, in_feature in enumerate(in_features):\n",
    "#     print(f'Training for exit layer: {ii+1}')\n",
    "#     precisions, recall, f1 = [], [], []\n",
    "#     learning_rate = 1e-3\n",
    "#     exit_model = IndividualEEModel(in_features=in_feature).to(device)\n",
    "#     criterion = nn.CrossEntropyLoss()\n",
    "#     optimizer = optim.SGD(exit_model.parameters(), lr=1e-3, momentum=0.9)\n",
    "#     epochs = 100\n",
    "#     ee_model_name = \"ind_ee_cifar10_s_conv.h5\"\n",
    "#     train(baseline, exit_model, ii, epochs, criterion, optimizer, train_loader, val_loader, ee_model_name)\n",
    "#     exit_model.load_state_dict(torch.load(ee_model_name, map_location='cpu'))\n",
    "#     exit_model.eval()\n",
    "#     correct = 0\n",
    "#     total = 0\n",
    "#     with torch.no_grad(): \n",
    "#         true_y, pred_y = [], []\n",
    "#         for i, data in enumerate(test_loader):\n",
    "#             images, labels = data\n",
    "#             images, labels = images.to(device), labels.to(device)\n",
    "#             _, outs = baseline(images)\n",
    "#             outputs = exit_model(outs[ii])\n",
    "#             _, predicted = torch.max(outputs.data, 1)\n",
    "#             total += labels.size(0)\n",
    "#             correct += (predicted == labels).sum().item()\n",
    "#             pred_y = pred_y + list(predicted.detach().cpu().numpy())\n",
    "#             true_y = true_y + list(labels.detach().cpu().numpy())\n",
    "#         report = classification_report(true_y, pred_y, output_dict=True)\n",
    "#         result_dict[\"accuracy\"].append(report[\"accuracy\"])\n",
    "#         for i, (key, value) in enumerate(report.items()):\n",
    "#             if i < 10:\n",
    "#                 precisions.append(value['precision'])\n",
    "#                 recall.append(value['recall'])\n",
    "#                 f1.append(value['f1-score'])\n",
    "#         result_dict[ii] = {\n",
    "#             'precision': precisions,\n",
    "#             'recall': recall,\n",
    "#             'f1': f1,\n",
    "#             'conf_mat': confusion_matrix(true_y, pred_y)\n",
    "#         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7dd6d5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axes = plt.subplots(len(in_features), 1, figsize=(15, 9))\n",
    "# class_names = ['plane', 'car', 'bird', 'cat','deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "# axes = axes.ravel()\n",
    "# bar_width = 0.25\n",
    "# for i, ax in enumerate(axes):\n",
    "#     precisions = result_dict[i]['precision']\n",
    "#     recall = result_dict[i]['recall']\n",
    "#     f1 = result_dict[i]['f1']\n",
    "#     r1 = np.arange(len(precisions))\n",
    "#     r2 = [x + bar_width for x in r1]\n",
    "#     r3 = [x + bar_width for x in r2]\n",
    "#     ax.bar(r1, precisions, color='blue', width=bar_width, edgecolor='white', label='Precision')\n",
    "#     ax.bar(r2, recall, color='green', width=bar_width, edgecolor#         x = self.fc1(x)='white', label='Recall')\n",
    "#     ax.bar(r3, f1, color='orange', width=bar_width, edgecolor='white', label='F1-score')\n",
    "#     ax.set_title(str(i))\n",
    "#     ax.set_xticks([r + bar_width for r in range(len(precisions))], class_names)\n",
    "#     ax.grid()\n",
    "# plt.xlabel('Class', fontweight='bold')\n",
    "# lines_labels = [ax.get_legend_handles_labels()]\n",
    "# lines, labels = [sum(lol, []) for lol in zip(*lines_labels)]\n",
    "# fig.legend(lines, labels, loc=\"upper center\", ncol=3, fontsize=18)\n",
    "# plt.tight_layout(pad=3)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aca82430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ind_accuracies = []\n",
    "# for i, accuracy in enumerate(result_dict['accuracy']):\n",
    "#     accuracy = round(accuracy, 4)\n",
    "#     precision = round(np.mean(result_dict[i][\"precision\"]), 4)\n",
    "#     recall = round(np.mean(result_dict[i][\"recall\"]), 4)\n",
    "#     f1 = round(np.mean(result_dict[i][\"f1\"]), 4)\n",
    "#     ind_accuracies.append(accuracy)\n",
    "#     print(f'Layer {i+1}: Accuracy: {accuracy} | Precision: {precision} | Recall: {recall} | f1-score: {f1}')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a48efb9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1]: t_loss: 2.33096 t_acc: 13.4 v_loss: 2.30459 v_acc: 12.42424\n",
      "Epoch[2]: t_loss: 2.29721 t_acc: 12.4 v_loss: 2.27758 v_acc: 16.14815\n",
      "Epoch[3]: t_loss: 2.268 t_acc: 16.0 v_loss: 2.25855 v_acc: 19.23906\n",
      "Epoch[4]: t_loss: 2.22886 t_acc: 19.0 v_loss: 2.23178 v_acc: 21.25926\n",
      "Epoch[5]: t_loss: 2.19963 t_acc: 19.0 v_loss: 2.19105 v_acc: 24.39057\n",
      "Epoch[6]: t_loss: 2.16883 t_acc: 22.6 v_loss: 2.15887 v_acc: 26.3569\n",
      "Epoch[7]: t_loss: 2.14906 t_acc: 24.2 v_loss: 2.12782 v_acc: 25.48148\n",
      "Epoch[8]: t_loss: 2.11109 t_acc: 23.0 v_loss: 2.07538 v_acc: 28.18855\n",
      "Epoch[9]: t_loss: 2.07317 t_acc: 27.6 v_loss: 2.04442 v_acc: 31.56229\n",
      "Epoch[10]: t_loss: 2.06075 t_acc: 29.2 v_loss: 2.08495 v_acc: 28.3569\n",
      "Epoch[11]: t_loss: 2.12115 t_acc: 24.8 v_loss: 2.04747 v_acc: 30.6532\n",
      "Epoch[12]: t_loss: 1.9317 t_acc: 33.2 v_loss: 2.03001 v_acc: 30.90909\n",
      "Epoch[13]: t_loss: 1.80458 t_acc: 42.0 v_loss: 2.00406 v_acc: 32.53872\n",
      "Epoch[14]: t_loss: 1.8171 t_acc: 41.6 v_loss: 2.01211 v_acc: 32.89562\n",
      "Epoch[15]: t_loss: 1.95169 t_acc: 34.2 v_loss: 1.97716 v_acc: 33.34007\n",
      "Epoch[16]: t_loss: 1.81082 t_acc: 39.6 v_loss: 1.95325 v_acc: 33.24579\n",
      "Epoch[17]: t_loss: 1.74183 t_acc: 40.6 v_loss: 1.93155 v_acc: 34.08754\n",
      "Epoch[18]: t_loss: 1.94274 t_acc: 34.4 v_loss: 1.92005 v_acc: 35.27946\n",
      "Epoch[19]: t_loss: 1.87424 t_acc: 38.4 v_loss: 1.91337 v_acc: 35.73737\n",
      "Epoch[20]: t_loss: 1.80061 t_acc: 39.4 v_loss: 1.89083 v_acc: 36.3771\n",
      "Epoch[21]: t_loss: 1.89 t_acc: 39.4 v_loss: 1.86126 v_acc: 36.53872\n",
      "Epoch[22]: t_loss: 1.89931 t_acc: 35.4 v_loss: 1.90265 v_acc: 34.68013\n",
      "Epoch[23]: t_loss: 1.7327 t_acc: 40.2 v_loss: 1.85745 v_acc: 36.28956\n",
      "Epoch[24]: t_loss: 1.62806 t_acc: 46.4 v_loss: 1.8915 v_acc: 36.20875\n",
      "Epoch[25]: t_loss: 1.66991 t_acc: 45.0 v_loss: 1.8637 v_acc: 37.27273\n",
      "Epoch[26]: t_loss: 1.82342 t_acc: 36.2 v_loss: 1.86263 v_acc: 36.74074\n",
      "Epoch[27]: t_loss: 1.72618 t_acc: 42.8 v_loss: 1.83735 v_acc: 37.09091\n",
      "Epoch[28]: t_loss: 1.84028 t_acc: 38.0 v_loss: 1.81677 v_acc: 37.67677\n",
      "Epoch[29]: t_loss: 1.67232 t_acc: 43.0 v_loss: 1.82415 v_acc: 37.6633\n",
      "Epoch[30]: t_loss: 1.73819 t_acc: 40.8 v_loss: 1.80803 v_acc: 38.82828\n",
      "Epoch[31]: t_loss: 1.94427 t_acc: 33.0 v_loss: 1.86493 v_acc: 36.74074\n",
      "Epoch[32]: t_loss: 1.58497 t_acc: 46.6 v_loss: 1.74342 v_acc: 41.26599\n",
      "Epoch[33]: t_loss: 1.53097 t_acc: 52.0 v_loss: 1.83532 v_acc: 36.70034\n",
      "Epoch[34]: t_loss: 1.7886 t_acc: 38.8 v_loss: 1.84294 v_acc: 35.89226\n",
      "Epoch[35]: t_loss: 1.88226 t_acc: 35.2 v_loss: 1.84433 v_acc: 36.30976\n",
      "Epoch[36]: t_loss: 1.62985 t_acc: 43.2 v_loss: 1.75534 v_acc: 39.85859\n",
      "Epoch[37]: t_loss: 1.65377 t_acc: 44.6 v_loss: 1.81275 v_acc: 37.92593\n",
      "Epoch[38]: t_loss: 2.01482 t_acc: 33.0 v_loss: 1.82541 v_acc: 37.88552\n",
      "Epoch[39]: t_loss: 1.88499 t_acc: 35.6 v_loss: 1.82115 v_acc: 37.43434\n",
      "Epoch[40]: t_loss: 1.54264 t_acc: 49.8 v_loss: 1.78895 v_acc: 38.75421\n",
      "Epoch[41]: t_loss: 1.44431 t_acc: 52.6 v_loss: 1.83348 v_acc: 36.73401\n",
      "Epoch[42]: t_loss: 1.76819 t_acc: 39.8 v_loss: 1.76501 v_acc: 39.31987\n",
      "Epoch[43]: t_loss: 1.73998 t_acc: 40.0 v_loss: 1.82078 v_acc: 37.33333\n",
      "Epoch[44]: t_loss: 1.69944 t_acc: 43.2 v_loss: 1.75071 v_acc: 39.72391\n",
      "Epoch[45]: t_loss: 1.70449 t_acc: 43.4 v_loss: 1.77343 v_acc: 39.05724\n",
      "Epoch[46]: t_loss: 1.55945 t_acc: 47.6 v_loss: 1.80451 v_acc: 37.69697\n",
      "Epoch[47]: t_loss: 1.44468 t_acc: 51.2 v_loss: 1.78037 v_acc: 38.47138\n",
      "Epoch[48]: t_loss: 1.55286 t_acc: 49.8 v_loss: 1.71675 v_acc: 41.14478\n",
      "Epoch[49]: t_loss: 1.67956 t_acc: 41.8 v_loss: 1.81009 v_acc: 37.69024\n",
      "Epoch[50]: t_loss: 1.68192 t_acc: 43.8 v_loss: 1.74318 v_acc: 39.75758\n",
      "Epoch[51]: t_loss: 1.84199 t_acc: 33.0 v_loss: 1.72426 v_acc: 40.2963\n",
      "Epoch[52]: t_loss: 1.55036 t_acc: 48.6 v_loss: 1.73638 v_acc: 40.05387\n",
      "Epoch[53]: t_loss: 1.57888 t_acc: 45.6 v_loss: 1.77483 v_acc: 39.19865\n",
      "Epoch[54]: t_loss: 1.68928 t_acc: 42.2 v_loss: 1.71507 v_acc: 41.33333\n",
      "Epoch[55]: t_loss: 1.27505 t_acc: 59.4 v_loss: 1.72021 v_acc: 41.44108\n",
      "Epoch[56]: t_loss: 1.53008 t_acc: 47.6 v_loss: 1.72392 v_acc: 41.12458\n",
      "Epoch[57]: t_loss: 1.44749 t_acc: 51.0 v_loss: 1.72909 v_acc: 40.72054\n",
      "Epoch[58]: t_loss: 1.39701 t_acc: 55.4 v_loss: 1.74354 v_acc: 40.59259\n",
      "Epoch[59]: t_loss: 1.78149 t_acc: 40.8 v_loss: 1.76772 v_acc: 39.2862\n",
      "Epoch[60]: t_loss: 1.28274 t_acc: 59.4 v_loss: 1.6987 v_acc: 41.6633\n",
      "Epoch[61]: t_loss: 1.64929 t_acc: 43.6 v_loss: 1.72885 v_acc: 41.49495\n",
      "Epoch[62]: t_loss: 1.78948 t_acc: 39.6 v_loss: 1.73151 v_acc: 40.88889\n",
      "Epoch[63]: t_loss: 1.68161 t_acc: 43.0 v_loss: 1.70099 v_acc: 41.72391\n",
      "Epoch[64]: t_loss: 1.82564 t_acc: 37.2 v_loss: 1.68943 v_acc: 41.90572\n",
      "Epoch[65]: t_loss: 1.41577 t_acc: 54.6 v_loss: 1.69718 v_acc: 41.60943\n",
      "Epoch[66]: t_loss: 1.28959 t_acc: 59.2 v_loss: 1.77747 v_acc: 38.55219\n",
      "Epoch[67]: t_loss: 1.66877 t_acc: 43.2 v_loss: 1.67965 v_acc: 42.20875\n",
      "Epoch[68]: t_loss: 1.45163 t_acc: 50.8 v_loss: 1.67255 v_acc: 42.76094\n",
      "Epoch[69]: t_loss: 1.56808 t_acc: 48.2 v_loss: 1.73543 v_acc: 40.35017\n",
      "Epoch[70]: t_loss: 1.51824 t_acc: 48.6 v_loss: 1.7378 v_acc: 40.10101\n",
      "Epoch[71]: t_loss: 1.44757 t_acc: 50.0 v_loss: 1.77537 v_acc: 38.32997\n",
      "Epoch[72]: t_loss: 1.25118 t_acc: 59.4 v_loss: 1.71759 v_acc: 40.3165\n",
      "Epoch[73]: t_loss: 1.4423 t_acc: 53.6 v_loss: 1.71123 v_acc: 40.78788\n",
      "Epoch[74]: t_loss: 1.21897 t_acc: 61.4 v_loss: 1.67938 v_acc: 42.3569\n",
      "Epoch[75]: t_loss: 1.4236 t_acc: 52.6 v_loss: 1.72665 v_acc: 40.18182\n",
      "Epoch[76]: t_loss: 1.34068 t_acc: 56.2 v_loss: 1.68305 v_acc: 41.84512\n",
      "Epoch[77]: t_loss: 1.813 t_acc: 38.8 v_loss: 1.68809 v_acc: 42.0202\n",
      "Epoch[78]: t_loss: 1.61419 t_acc: 43.6 v_loss: 1.71151 v_acc: 40.85522\n",
      "Epoch[79]: t_loss: 1.4282 t_acc: 52.6 v_loss: 1.64093 v_acc: 43.33333\n",
      "Epoch[80]: t_loss: 1.57624 t_acc: 48.4 v_loss: 1.67548 v_acc: 42.3771\n",
      "Epoch[81]: t_loss: 1.36374 t_acc: 54.6 v_loss: 1.68154 v_acc: 42.47811\n",
      "Epoch[82]: t_loss: 1.75459 t_acc: 37.8 v_loss: 1.66792 v_acc: 42.75421\n",
      "Epoch[83]: t_loss: 1.44724 t_acc: 50.4 v_loss: 1.70522 v_acc: 41.26599\n",
      "Epoch[84]: t_loss: 1.41017 t_acc: 52.6 v_loss: 1.75641 v_acc: 39.81818\n",
      "Epoch[85]: t_loss: 1.57082 t_acc: 46.8 v_loss: 1.71475 v_acc: 41.3266\n",
      "Epoch[86]: t_loss: 1.43447 t_acc: 49.0 v_loss: 1.64111 v_acc: 43.62963\n",
      "Epoch[87]: t_loss: 1.30033 t_acc: 56.6 v_loss: 1.70925 v_acc: 40.86195\n",
      "Epoch[88]: t_loss: 1.54494 t_acc: 49.4 v_loss: 1.72755 v_acc: 40.20202\n",
      "Epoch[89]: t_loss: 1.35536 t_acc: 53.8 v_loss: 1.66099 v_acc: 42.9899\n",
      "Epoch[90]: t_loss: 1.72918 t_acc: 43.0 v_loss: 1.67355 v_acc: 42.6532\n",
      "Epoch[91]: t_loss: 1.25545 t_acc: 58.4 v_loss: 1.70516 v_acc: 41.45455\n",
      "Epoch[92]: t_loss: 1.39172 t_acc: 53.8 v_loss: 1.68329 v_acc: 42.12795\n",
      "Epoch[93]: t_loss: 1.75729 t_acc: 39.4 v_loss: 1.6583 v_acc: 42.74074\n",
      "Epoch[94]: t_loss: 1.38183 t_acc: 54.4 v_loss: 1.63894 v_acc: 43.62963\n",
      "Epoch[95]: t_loss: 1.37043 t_acc: 57.2 v_loss: 1.6564 v_acc: 43.13131\n",
      "Epoch[96]: t_loss: 1.2406 t_acc: 59.2 v_loss: 1.67684 v_acc: 42.76768\n",
      "Epoch[97]: t_loss: 1.61253 t_acc: 45.4 v_loss: 1.7256 v_acc: 41.06397\n",
      "Epoch[98]: t_loss: 1.78149 t_acc: 39.4 v_loss: 1.68024 v_acc: 41.99327\n",
      "Epoch[99]: t_loss: 1.61438 t_acc: 45.8 v_loss: 1.71444 v_acc: 40.9697\n",
      "Epoch[100]: t_loss: 1.55046 t_acc: 49.2 v_loss: 1.68966 v_acc: 42.02694\n",
      "Finished Training\n",
      "Best model saved at epoch:  94\n"
     ]
    }
   ],
   "source": [
    "result_dict = {}\n",
    "result_dict[\"accuracy\"] = []\n",
    "in_features = [0]\n",
    "for ii, in_feature in enumerate(in_features):\n",
    "    precisions, recall, f1 = [], [], []\n",
    "    learning_rate = 5e-3\n",
    "    exit_model = GeneralEEModel().to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(exit_model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "    epochs = 100\n",
    "    ee_model_name = \"gen_ee_cifar10_s_new.h5\"\n",
    "    train(baseline, exit_model, ii, epochs, criterion, optimizer, \n",
    "          train_loader, val_loader, ee_model_name, gen_ee=True)\n",
    "    exit_model.load_state_dict(torch.load(ee_model_name, map_location='cpu'))\n",
    "    exit_model.eval()\n",
    "    correct = 0\n",
    "    total = 0#         x = self.fc1(x)\n",
    "    with torch.no_grad(): \n",
    "        true_y, pred_y = [], []\n",
    "        for i, data in enumerate(test_loader):\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            _, outs = baseline(images)\n",
    "            outs, _ = simulate_exit(outs)\n",
    "            outputs = exit_model(outs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            pred_y = pred_y + list(predicted.detach().cpu().numpy())\n",
    "            true_y = true_y + list(labels.detach().cpu().numpy())\n",
    "        report = classification_report(true_y, pred_y, output_dict=True)\n",
    "        result_dict[\"accuracy\"].append(report[\"accuracy\"])\n",
    "        for i, (key, value) in enumerate(report.items()):\n",
    "            if i < 10:\n",
    "                precisions.append(value['precision'])\n",
    "                recall.append(value['recall'])\n",
    "                f1.append(value['f1-score'])\n",
    "        result_dict[ii] = {\n",
    "            'precision': precisions,\n",
    "            'recall': recall,\n",
    "            'f1': f1,\n",
    "            'conf_mat': confusion_matrix(true_y, pred_y)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1aa71f42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x900 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(len(in_features), 1, figsize=(15, 9))\n",
    "class_names = ['plane', 'car', 'bird', 'cat','deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "bar_width = 0.25#         x = self.fc1(x)\n",
    "i = 0\n",
    "precisions = result_dict[i]['precision']\n",
    "recall = result_dict[i]['recall']\n",
    "f1 = result_dict[i]['f1']\n",
    "r1 = np.arange(len(precisions))\n",
    "r2 = [x + bar_width for x in r1]\n",
    "r3 = [x + bar_width for x in r2]\n",
    "ax.bar(r1, precisions, color='blue', width=bar_width, edgecolor='white', label='Precision')\n",
    "ax.bar(r2, recall, color='green', width=bar_width, edgecolor='white', label='Recall')\n",
    "ax.bar(r3, f1, color='orange', width=bar_width, edgecolor='white', label='F1-score')\n",
    "ax.set_title(str(i))\n",
    "ax.set_xticks([r + bar_width for r in range(len(precisions))], class_names)\n",
    "ax.grid()\n",
    "plt.xlabel('Class', fontweight='bold')\n",
    "lines_labels = [ax.get_legend_handles_labels()]\n",
    "lines, labels = [sum(lol, []) for lol in zip(*lines_labels)]\n",
    "fig.legend(lines, labels, loc=\"upper center\", ncol=3, fontsize=18)\n",
    "plt.tight_layout(pad=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "57c94970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: 1 | Accuracy: 0.3121\n",
      "Layer: 2 | Accuracy: 0.4531\n",
      "Layer: 3 | Accuracy: 0.5157\n"
     ]
    }
   ],
   "source": [
    "accuracies = []\n",
    "for choice in range(3):\n",
    "    true_y, pred_y = [], []\n",
    "    for i, data in enumerate(test_loader):#         x = self.fc1(x)\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        _, outs = baseline(images)\n",
    "        outs, _ = simulate_exit(outs, choice=choice)\n",
    "        outputs = exit_model(outs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        pred_y = pred_y + list(predicted.detach().cpu().numpy())\n",
    "        true_y = true_y + list(labels.detach().cpu().numpy())\n",
    "    report = classification_report(true_y, pred_y, output_dict=True)\n",
    "    accuracies.append(report[\"accuracy\"])\n",
    "    print(f'Layer: {choice+1} | Accuracy: {report[\"accuracy\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "478e3994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(15, 7))\n",
    "# x = [1, 2, 3]\n",
    "# plt.plot(x, accuracies, \n",
    "#          marker='o', markerfacecolor='orange', markersize=12, color='red', linewidth=4,\n",
    "#          label=\"General EE\"\n",
    "#         )\n",
    "# plt.plot(x, ind_accuracies, \n",
    "#          marker='o', markerfacecolor='blue', markersize=12, color='skyblue', linewidth=4,\n",
    "#          label=\"Non-general EE\"\n",
    "#         )\n",
    "# plt.axhline(0.7067, marker='', color='olive', linewidth=4, linestyle='dashed', label=\"Baseline\")\n",
    "# plt.xlabel(\"Exit Layer\", fontsize=24)\n",
    "# plt.ylabel(\"Accuracy\", fontsize=24)\n",
    "# plt.xticks(fontsize=18)\n",
    "# plt.yticks(fontsize=18)\n",
    "# plt.grid(color='k', linestyle='--', linewidth=1)\n",
    "# plt.legend(loc=\"best\", prop={'size': 18})\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "42739825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3121, 0.4531, 0.5157]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11af70c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"gen_ee_cifar10_m_5.h5\", map_location='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f667e0e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 30, 30]           1,792\n",
      "         MaxPool2d-2           [-1, 64, 15, 15]               0\n",
      "            Conv2d-3          [-1, 128, 13, 13]          73,856\n",
      "         MaxPool2d-4            [-1, 128, 6, 6]               0\n",
      "            Conv2d-5             [-1, 64, 4, 4]          73,792\n",
      "         MaxPool2d-6             [-1, 64, 2, 2]               0\n",
      "           Flatten-7                  [-1, 256]               0\n",
      "            Linear-8                  [-1, 256]          65,792\n",
      "            Linear-9                   [-1, 64]          16,448\n",
      "           Linear-10                   [-1, 10]             650\n",
      "================================================================\n",
      "Total params: 232,330\n",
      "Trainable params: 232,330\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.76\n",
      "Params size (MB): 0.89\n",
      "Estimated Total Size (MB): 1.66\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "# Assuming the model architecture is GeneralEEModel\n",
    "model = Baseline().to(device)\n",
    "model.load_state_dict(torch.load(\"cifar10_baseline_s_new.h5\", map_location='cpu'))\n",
    "\n",
    "summary(model, (3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "292acc65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('fc.weight',\n",
       "              tensor([[ 0.0192,  0.0674,  0.0463,  ...,  0.0044, -0.0070, -0.0102],\n",
       "                      [-0.0614, -0.0483,  0.0030,  ..., -0.0119, -0.0002, -0.0107],\n",
       "                      [ 0.0025, -0.0012, -0.0016,  ...,  0.0008, -0.0153,  0.0317],\n",
       "                      ...,\n",
       "                      [ 0.0122,  0.0330, -0.0623,  ..., -0.0050,  0.0013,  0.0096],\n",
       "                      [ 0.0667,  0.0778,  0.0511,  ..., -0.0216, -0.0452, -0.0256],\n",
       "                      [ 0.0316, -0.0060, -0.0137,  ...,  0.0116, -0.0008, -0.0150]],\n",
       "                     device='cuda:0')),\n",
       "             ('fc.bias',\n",
       "              tensor([-0.0309, -0.1836,  0.1168,  0.0379,  0.2312,  0.0394,  0.0783, -0.0826,\n",
       "                       0.0475, -0.1377], device='cuda:0'))])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fb209a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_flex_vit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
