{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Compress Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sparsecomp import compress_NN_models\n",
    "import torch\n",
    "from conversion import save_compressed_model\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"GPU-949091da-1455-7238-7234-08221ff71c62\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_full_model(model):\n",
    "    assert isinstance(model, nn.Module), \"The model is not a subclass of torch.nn.Module\"\n",
    "    kb = 1000\n",
    "    model_size = 0\n",
    "    params = 0\n",
    "    for name, param in model.named_parameters():\n",
    "        layer_size = param.nelement() * param.element_size()\n",
    "        model_size += layer_size\n",
    "        # print(name,\"\\t\", param.nelement(), \"\\t\", param.element_size(),\"\\t\", layer_size / kb, \"KB\")\n",
    "\n",
    "    for name, buffer in model.named_buffers():\n",
    "        layer_size = buffer.nelement() * buffer.element_size()\n",
    "        model_size += layer_size\n",
    "        # print(name,\"\\t\", layer_size / kb, \"KB\")\n",
    "    # print(\"Model Size:\", model_size / kb, \"KB\")\n",
    "\n",
    "    params = sum(p.numel() for p in model.parameters())\n",
    "    # print(\"Model Params:\", params)\n",
    "\n",
    "    return (model_size / kb), params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Baseline_compressed(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Baseline_compressed, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=\"valid\")\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=\"valid\")\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "        self.conv3 = nn.Conv2d(in_channels=128, out_channels=64, kernel_size=3, padding=\"valid\")\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(in_features=256, out_features=25, bias=False),\n",
    "            nn.Linear(in_features=25, out_features=256)\n",
    "        )\n",
    "        self.fc2 = nn.Linear(in_features=256, out_features=64)\n",
    "        self.fc3 = nn.Linear(in_features=64, out_features=10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        exit_outputs = []\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool1(x)\n",
    "        exit_outputs.append(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool2(x)\n",
    "        exit_outputs.append(x)\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool3(x)\n",
    "        exit_outputs.append(x)\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "        \n",
    "        x = self.fc1[0](x)\n",
    "        x = self.fc1[1](x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x, exit_outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Baseline(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Baseline, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=\"valid\")\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=\"valid\")\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "        self.conv3 = nn.Conv2d(in_channels=128, out_channels=64, kernel_size=3, padding=\"valid\")\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=256, out_features=256)\n",
    "        self.fc2 = nn.Linear(in_features=256, out_features=64)\n",
    "        self.fc3 = nn.Linear(in_features=64, out_features=10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        exit_outputs = []\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool1(x)\n",
    "        exit_outputs.append(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool2(x)\n",
    "        exit_outputs.append(x)\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool3(x)\n",
    "        exit_outputs.append(x)\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x, exit_outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for S_earlyexit_model\n",
    "class GeneralEEModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GeneralEEModel, self).__init__()\n",
    "        self.pool_kernels = [\n",
    "            (1, 6, 6), (1, 3, 3), (1, 1, 1)\n",
    "        ]\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.dropout = nn.Dropout(p=0.4)\n",
    "        self.fc = nn.Linear(in_features=1024, out_features=10)\n",
    "    \n",
    "    def forward(self, x, inference=False):\n",
    "        pooled_outs = []\n",
    "        for layer, out in enumerate(x):\n",
    "            pool_3d = nn.MaxPool3d(kernel_size=self.pool_kernels[layer])\n",
    "            pooled_outs.append(pool_3d(x))\n",
    "        x = torch.cat(pooled_outs, dim=1)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout(x)\n",
    "        scores = self.fc(x)\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline-S Model Size: 929.32 KB\n",
      "Baseline-S Model Params: 232330\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "# Define your model (assuming GeneralEEModel is defined elsewhere)\n",
    "# model = GeneralEEModel().to(device)\n",
    "model = Baseline().to(device)\n",
    "model_size, params = print_full_model(model)\n",
    "print(\"Baseline-S Model Size:\", model_size, \"KB\")\n",
    "print(\"Baseline-S Model Params:\", params)\n",
    "\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "dataset = CIFAR10(root='./data', download=True, transform=ToTensor())\n",
    "test_dataset = CIFAR10(root='./data', train=False, transform=ToTensor())\n",
    "\n",
    "# # Define data loaders\n",
    "# batch_size = 128\n",
    "# val_size = 5000\n",
    "# train_size = len(dataset) - val_size\n",
    "# train_ds, val_ds = random_split(dataset, [train_size, val_size])\n",
    "# train_loader = DataLoader(train_ds, batch_size, shuffle=True, num_workers=4)\n",
    "# val_loader = DataLoader(val_ds, batch_size * 2, num_workers=4)\n",
    "# test_loader = DataLoader(test_dataset, batch_size * 2, num_workers=4)\n",
    "\n",
    "# # Define other parameters\n",
    "# target_size = 32  # Target size in KB\n",
    "# num_epochs = 10\n",
    "# learning_rate = 0.001\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "# regularizerParam = 0.0\n",
    "# compressionStep = 0.1\n",
    "# initialCompressionStep = 0.1\n",
    "# fastCompression = False\n",
    "# modelName = \"_32KB\"\n",
    "# device = \"cpu\"\n",
    "# accuracyAware = True\n",
    "# layersFactorization = True\n",
    "# calculateInputs = None\n",
    "\n",
    "# # Call the compress_NN_models function\n",
    "# compress_NN_models(\n",
    "#     model, target_size, train_loader, test_loader,\n",
    "#     val_loader=val_loader, num_epochs=num_epochs, learning_rate=learning_rate,\n",
    "#     criterion=criterion, regularizerParam=regularizerParam, compressionStep=compressionStep,\n",
    "#     initialCompressionStep=initialCompressionStep, fastCompression=fastCompression,\n",
    "#     modelName=modelName, device=device, accuracyAware=accuracyAware,\n",
    "#     layersFactorization=layersFactorization, calculateInputs=calculateInputs\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline-S Model Size: 718.376 KB\n",
      "Baseline-S Model Params: 179594\n",
      "Directory '_32KB_C_code' created\n",
      "Directory '_32KB_C_code/headers' created\n",
      "Values: 0 0\n",
      "\n",
      "Iterating over the module:\n",
      "\n",
      "Weight shape: torch.Size([64, 3, 3, 3])\n",
      "Shape output of the module: torch.Size([1, 64, 30, 30])\n",
      "Layer conv 1 Values: 1 1\n",
      "Shape output of the module: torch.Size([1, 64, 15, 15])\n",
      "Output Dimension: 4\n",
      "Layer pooling 1 Values: 2 2\n",
      "Weight shape: torch.Size([128, 64, 3, 3])\n",
      "Shape output of the module: torch.Size([1, 128, 13, 13])\n",
      "Layer conv 2 Values: 3 3\n",
      "Shape output of the module: torch.Size([1, 128, 6, 6])\n",
      "Output Dimension: 4\n",
      "Layer pooling 2 Values: 4 4\n",
      "Weight shape: torch.Size([64, 128, 3, 3])\n",
      "Shape output of the module: torch.Size([1, 64, 4, 4])\n",
      "Layer conv 3 Values: 5 5\n",
      "Shape output of the module: torch.Size([1, 64, 2, 2])\n",
      "Output Dimension: 4\n",
      "Layer pooling 3 Values: 6 6\n",
      "Shape output of the module: torch.Size([1, 256])\n",
      "Layer flatten 1 Values: 7 7\n",
      "Weight shape: torch.Size([25, 256])\n",
      "Shape output of the module: torch.Size([1, 25])\n",
      "Layer fc 1 Values: 8 8\n",
      "Weight shape: torch.Size([256, 25])\n",
      "Shape output of the module: torch.Size([1, 256])\n",
      "Layer fc 2 Values: 9 9\n",
      "Weight shape: torch.Size([64, 256])\n",
      "Shape output of the module: torch.Size([1, 64])\n",
      "Layer fc 3 Values: 10 10\n",
      "Weight shape: torch.Size([10, 64])\n",
      "Shape output of the module: torch.Size([1, 10])\n",
      "Layer fc 4 Values: 11 11\n",
      "\n",
      "Checked 11 / 11 layers\n",
      "Saved 11 / 11 layers\n",
      "\n",
      "Ignored these modules:\n",
      "[]\n",
      "\n",
      "\n",
      "Finished Saving the Model\n"
     ]
    }
   ],
   "source": [
    "model = Baseline_compressed().to(device)\n",
    "# print('Expected model keys: \\n',model.state_dict().keys())  # Expected keys\n",
    "# print('loaded model keys: \\n',torch.load(\"compressed_model_186.h5\").keys())  # Loaded keys\n",
    "model.load_state_dict(torch.load(\"/home/mal/DScale/momin_flex_nns/freeml/FreeML/SparseComp/_32KB_30.h5\", map_location='cpu'))\n",
    "model_size, params = print_full_model(model)\n",
    "print(\"Baseline-S Model Size:\", model_size, \"KB\")\n",
    "print(\"Baseline-S Model Params:\", params)\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert to tensor\n",
    "])\n",
    "\n",
    "# Download dataset and get a single sample\n",
    "single_sample, _ = dataset[0]  # Extract first sample (image, label)\n",
    "\n",
    "# Add batch dimension\n",
    "single_sample = single_sample.unsqueeze(0)  # Shape: (1, 3, 32, 32)\n",
    "\n",
    "save_compressed_model(model, 'csr', input_data=single_sample, directory='_32KB_C_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 30, 30]           1,792\n",
      "         MaxPool2d-2           [-1, 64, 15, 15]               0\n",
      "            Conv2d-3          [-1, 128, 13, 13]          73,856\n",
      "         MaxPool2d-4            [-1, 128, 6, 6]               0\n",
      "            Conv2d-5             [-1, 64, 4, 4]          73,792\n",
      "         MaxPool2d-6             [-1, 64, 2, 2]               0\n",
      "           Flatten-7                  [-1, 256]               0\n",
      "            Linear-8                   [-1, 25]           6,400\n",
      "            Linear-9                  [-1, 256]           6,656\n",
      "           Linear-10                   [-1, 64]          16,448\n",
      "           Linear-11                   [-1, 10]             650\n",
      "================================================================\n",
      "Total params: 179,594\n",
      "Trainable params: 179,594\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.76\n",
      "Params size (MB): 0.69\n",
      "Estimated Total Size (MB): 1.46\n",
      "----------------------------------------------------------------\n",
      "---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "Actual active weights per layer\n",
      "\n",
      "---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "conv1 1728\n",
      "conv2 282\n",
      "conv3 313\n",
      "fc1.0 307\n",
      "fc1.1 201\n",
      "fc2 784\n",
      "fc3 640\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "model = Baseline_compressed().to(device)\n",
    "# print('Expected model keys: \\n',model.state_dict().keys())  # Expected keys\n",
    "# print('loaded model keys: \\n',torch.load(\"compressed_model_186.h5\").keys())  # Loaded keys\n",
    "model.load_state_dict(torch.load(\"/home/mal/DScale/momin_flex_nns/freeml/FreeML/SparseComp/models/32KB/_32KB_30.h5\", map_location='cpu'))\n",
    "summary(model, (3, 32, 32))\n",
    "print(100*'-','\\n')\n",
    "print(\"Actual active weights per layer\\n\")\n",
    "print(100*'-','\\n')\n",
    "for name, layer in model.named_modules():\n",
    "    if isinstance(layer, (torch.nn.Conv2d, torch.nn.Linear)):\n",
    "        print(name, layer.weight.data.nonzero().size(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_flex_vit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
